{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommender Systems \n",
    "-- predicting if a user like a movie or not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.parallel\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing datasets \n",
    "\n",
    "-- details regarding the dataset is given in readme file attached  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0                                   1                             2\n",
      "0  1                    Toy Story (1995)   Animation|Children's|Comedy\n",
      "1  2                      Jumanji (1995)  Adventure|Children's|Fantasy\n",
      "2  3             Grumpier Old Men (1995)                Comedy|Romance\n",
      "3  4            Waiting to Exhale (1995)                  Comedy|Drama\n",
      "4  5  Father of the Bride Part II (1995)                        Comedy\n",
      "(3883, 3)\n"
     ]
    }
   ],
   "source": [
    "movies = pd.read_csv('DataSet/ml-1m/movies.dat', sep = '::', header = None, engine= 'python', \n",
    "                     encoding='latin-1')\n",
    "print(movies.head())\n",
    "print(movies.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0  1   2   3      4\n",
      "0  1  F   1  10  48067\n",
      "1  2  M  56  16  70072\n",
      "2  3  M  25  15  55117\n",
      "3  4  M  45   7  02460\n",
      "4  5  M  25  20  55455\n",
      "(6040, 5)\n"
     ]
    }
   ],
   "source": [
    "user = pd.read_csv('DataSet/ml-1m/users.dat', sep = '::', header = None, engine= 'python', \n",
    "                     encoding='latin-1')\n",
    "print(user.head())\n",
    "print(user.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0     1  2          3\n",
      "0  1  1193  5  978300760\n",
      "1  1   661  3  978302109\n",
      "2  1   914  3  978301968\n",
      "3  1  3408  4  978300275\n",
      "4  1  2355  5  978824291\n",
      "(1000209, 4)\n"
     ]
    }
   ],
   "source": [
    "rating = pd.read_csv('DataSet/ml-1m/ratings.dat', sep = '::', header = None, engine= 'python', \n",
    "                     encoding='latin-1')\n",
    "print(rating.head())\n",
    "print(rating.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>1.1</th>\n",
       "      <th>5</th>\n",
       "      <th>874965758</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>876893171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>878542960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>876893119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>889751712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>875071561</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   1  1.1  5  874965758\n",
       "0  1    2  3  876893171\n",
       "1  1    3  4  878542960\n",
       "2  1    4  3  876893119\n",
       "3  1    5  3  889751712\n",
       "4  1    7  4  875071561"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we are taking our training set from u1.base of 'ml - 100k' data and u1.test as test set\n",
    "train = pd.read_csv('DataSet/ml-100k/u1.base', sep= '\\t')\n",
    "train.head()\n",
    "# User||MoviesID||Rating||Timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.array(train, dtype='int')\n",
    "test = pd.read_csv('DataSet/ml-100k/u1.test', sep= '\\t')\n",
    "test = np.array(test, dtype='int')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of users and movies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "943\n",
      "1682\n"
     ]
    }
   ],
   "source": [
    "nb_users = int(max(max(train[:, 0]), max(test[:,0])))\n",
    "nb_movies = int(max(max(train[:, 1]), max(test[:,1])))\n",
    "print(nb_users)\n",
    "print(nb_movies)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing the data into an array with user as rows and movies as columns so as to put in our BMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(data):\n",
    "    new_df = []\n",
    "    for id_users in range(1, nb_users + 1):\n",
    "        id_movies = data[:, 1][data[:, 0] == id_users]\n",
    "        id_rating = data[:, 2][data[:, 0] == id_users]\n",
    "        ratings = np.zeros(nb_movies)\n",
    "        ratings[id_movies-1] = id_rating\n",
    "        new_df.append(list(ratings))\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = convert(train)\n",
    "test = convert(test)\n",
    "# len(test[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting into tensor for pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = torch.FloatTensor(train)\n",
    "test = torch.FloatTensor(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting all the rating to binary because we are predicting whether a user like a movie or not\n",
    "# Our RBM predict the values of unrated movies.\n",
    "train[train == 0] = -1\n",
    "train[train == 1] = 0\n",
    "train[train == 2] = 0\n",
    "train[train >= 3] = 1\n",
    "test[test == 0] = -1\n",
    "test[test == 1] = 0\n",
    "test[test == 2] = 0\n",
    "test[test >= 3] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.,  1.,  1.,  ..., -1., -1., -1.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building RBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RBM():\n",
    "    def __init__(self, nv, nh):\n",
    "        self.W = torch.randn(nh, nv)\n",
    "        self.a = torch.randn(1, nh)\n",
    "        self.b = torch.randn(1, nv)\n",
    "\n",
    "    def sample_h(self, x):\n",
    "        wx = torch.mm(x, self.W.t())\n",
    "        activation = wx + self.a.expand_as(wx)\n",
    "        p_h_given_v = torch.sigmoid(activation)\n",
    "        return p_h_given_v, torch.bernoulli(p_h_given_v)\n",
    "    # the torch.bernaulli return a tensor containing all the binary value of node depending upon the value of probability. whether they \n",
    "    # are activated or not.\n",
    "\n",
    "    def sample_v(self, y):\n",
    "        wy = torch.mm(y, self.W)\n",
    "        activation = wy + self.b.expand_as(wy)\n",
    "        p_v_given_h = torch.sigmoid(activation)\n",
    "        return p_v_given_h, torch.bernoulli(p_v_given_h)\n",
    "    # this function return the values of visible nodes in a form of vector or tensor\n",
    "\n",
    "    # contrastive divergence of Gibbs Sampling \n",
    "    #  vk --> visible node obtained after k CDs \n",
    "    def train(self, v0, vk, ph0, phk):\n",
    "        self.W += (torch.mm(v0.t(), ph0) - torch.mm(vk.t(), phk)).t()\n",
    "        self.b += torch.sum((v0 - vk), 0)\n",
    "        self.a += torch.sum((ph0 - phk), 0)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "nv = len(train[0])\n",
    "# nh depends upon our size\n",
    "nh = 500\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500, 1682])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rbm = RBM(nv, nh)\n",
    "rbm.W.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0 || loss: 0.33229896426200867 \n",
      "epoch : 1 || loss: 0.2547893524169922 \n",
      "epoch : 2 || loss: 0.24982108175754547 \n",
      "epoch : 3 || loss: 0.24887531995773315 \n",
      "epoch : 4 || loss: 0.24731135368347168 \n",
      "epoch : 5 || loss: 0.24653227627277374 \n",
      "epoch : 6 || loss: 0.24604511260986328 \n",
      "epoch : 7 || loss: 0.24607239663600922 \n",
      "epoch : 8 || loss: 0.24602049589157104 \n",
      "epoch : 9 || loss: 0.24376767873764038 \n",
      "epoch : 10 || loss: 0.24484126269817352 \n",
      "epoch : 11 || loss: 0.24502597749233246 \n",
      "epoch : 12 || loss: 0.24501731991767883 \n",
      "epoch : 13 || loss: 0.24506384134292603 \n",
      "epoch : 14 || loss: 0.24542362987995148 \n",
      "epoch : 15 || loss: 0.24472488462924957 \n",
      "epoch : 16 || loss: 0.2463141828775406 \n",
      "epoch : 17 || loss: 0.24213004112243652 \n",
      "epoch : 18 || loss: 0.2434638887643814 \n",
      "epoch : 19 || loss: 0.24396030604839325 \n"
     ]
    }
   ],
   "source": [
    "epoch = 20\n",
    "for i in range(0, epoch):\n",
    "    train_loss = 0\n",
    "    cnt = 0. # cnt in float\n",
    "    for id_users in range(0, nb_users - batch_size, batch_size):\n",
    "        vk = train[id_users:id_users+batch_size]\n",
    "        # v0 is the target which is used for comparision\n",
    "        v0 = train[id_users:id_users+batch_size]\n",
    "        ph0,_ = rbm.sample_h(v0)\n",
    "        for k in range(20):\n",
    "            _,hk = rbm.sample_h(vk)\n",
    "            _,vk = rbm.sample_v(hk)\n",
    "            # updation should not be done on the movies which user doesn't watch\n",
    "            vk[v0 < 0] = v0[v0<0]\n",
    "        phk,_ = rbm.sample_h(vk)   \n",
    "        rbm.train(v0, vk, ph0, phk)\n",
    "        train_loss += torch.mean(torch.abs(vk[vk>=0] - v0[v0>=0]))\n",
    "        cnt += 1.\n",
    "    print(f\"epoch : {i} || loss: {train_loss/cnt} \")   # printing the cumlative normalised loss \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 0.2472657859325409 \n"
     ]
    }
   ],
   "source": [
    "test_loss = 0\n",
    "cnt = 0. # cnt in float\n",
    "for id_users in range(nb_users):\n",
    "    v = train[id_users:id_users+1]\n",
    "    # vt is the target which is used for comparision\n",
    "    vt = test[id_users:id_users+1]\n",
    "    if len(vt[vt >= 0]) > 0:\n",
    "        _,h = rbm.sample_h(v)\n",
    "        _,v = rbm.sample_v(h)\n",
    "        test_loss += torch.mean(torch.abs(v[vt>=0] - vt[vt>=0]))\n",
    "        cnt += 1.\n",
    "print(f\"test loss: {test_loss/cnt} \")   # printing the cumlative normalised loss \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
